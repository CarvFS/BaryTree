#!/bin/bash
# Begin LSF Directives
#BSUB -P GEN135
#BSUB -W 1:00
#BSUB -nnodes 4
#BSUB -alloc_flags gpumps
#BSUB -J cpu_testing
#BSUB -o cpu_testing.%J
#BSUB -e cpu_testing.%J

# -n is number of resource sets
# -a is number of MPI tasks per resource set
# -c is number of CPU cores per resource set (i.e., number of total threads!)
# -g is number of GPUs


cd $SHARED/


N=100000
THETA=0.8
ORDER=8
CLUSTERSIZE=4000          
BATCHSIZE=4000
 
KERNEL=0
KAPPA=0.0

NZ=2
NY=3
for NX in 1 2 4
do
#NY=$NX
#NZ=$NX
NP=$(($NX * $NY * $NZ))
echo $NP
SOURCES=/gpfs/wolf/proj-shared/gen135/BaryTree/randomPoints/S${N}_${NX}x_${NY}y_${NZ}z.bin
TARGETS=/gpfs/wolf/proj-shared/gen135/BaryTree/randomPoints/T${N}_${NX}x_${NY}y_${NZ}z.bin
OFFSETS=/gpfs/wolf/proj-shared/gen135/BaryTree/randomPoints/offsets${N}_${NX}x_${NY}y_${NZ}z.bin
DIRECT=/gpfs/wolf/proj-shared/gen135/BaryTree/randomPoints/direct_gpu_${N}.bin
OUTPUT=/gpfs/wolf/proj-shared/gen135/BaryTree/randomPoints/tree_gpu_${N}.csv
jsrun -n ${NP} -a 1 -c 1 -g 0 ~/.local/bin/tree-distributed-cpu $SOURCES $TARGETS $OFFSETS $OFFSETS $DIRECT $OUTPUT $N $N $THETA $ORDER $CLUSTERSIZE $BATCHSIZE $KERNEL $KAPPA
done



